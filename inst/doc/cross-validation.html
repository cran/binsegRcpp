<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Cross-validation</title>
<style type="text/css">
/**
 * Prism.s theme ported from highlight.js's xcode style
 */
pre code {
  padding: 1em;
}
.token.comment {
  color: #007400;
}
.token.punctuation {
  color: #999;
}
.token.tag,
.token.selector {
  color: #aa0d91;
}
.token.boolean,
.token.number,
.token.constant,
.token.symbol {
  color: #1c00cf;
}
.token.property,
.token.attr-name,
.token.string,
.token.char,
.token.builtin {
  color: #c41a16;
}
.token.inserted {
  background-color: #ccffd8;
}
.token.deleted {
  background-color: #ffebe9;
}
.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
  color: #9a6e3a;
}
.token.atrule,
.token.attr-value,
.token.keyword {
  color: #836c28;
}
.token.function,
.token.class-name {
  color: #DD4A68;
}
.token.regex,
.token.important,
.token.variable {
  color: #5c2699;
}
.token.important,
.token.bold {
  font-weight: bold;
}
.token.italic {
  font-style: italic;
}
</style>
<style type="text/css">
body {
  font-family: sans-serif;
  max-width: 800px;
  margin: auto;
  padding: 1em;
  line-height: 1.5;
  box-sizing: border-box;
}
body, .footnotes, code { font-size: .9em; }
li li { font-size: .95em; }
*, *:before, *:after {
  box-sizing: inherit;
}
pre, img { max-width: 100%; }
pre, pre:hover {
  white-space: pre-wrap;
  word-break: break-all;
}
pre code {
  display: block;
  overflow-x: auto;
}
code { font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace; }
:not(pre) > code, code[class] { background-color: #F8F8F8; }
code.language-undefined, pre > code:not([class]) {
  background-color: inherit;
  border: 1px solid #eee;
}
table {
  margin: auto;
  border-top: 1px solid #666;
}
table thead th { border-bottom: 1px solid #ddd; }
th, td { padding: 5px; }
thead, tfoot, tr:nth-child(even) { background: #eee; }
blockquote {
  color: #666;
  margin: 0;
  padding-left: 1em;
  border-left: 0.5em solid #eee;
}
hr, .footnotes::before { border: 1px dashed #ddd; }
.frontmatter { text-align: center; }
#TOC .numbered li { list-style: none; }
#TOC .numbered { padding-left: 0; }
#TOC .numbered ul { padding-left: 1em; }
table, .body h2 { border-bottom: 1px solid #666; }
.body .appendix, .appendix ~ h2 { border-bottom-style: dashed; }
.footnote-ref a::before { content: "["; }
.footnote-ref a::after { content: "]"; }
.footnotes::before {
  content: "";
  display: block;
  max-width: 20em;
}

@media print {
  body {
    font-size: 12pt;
    max-width: 100%;
  }
  tr, img { page-break-inside: avoid; }
}
@media only screen and (min-width: 992px) {
  pre { white-space: pre; }
}
</style>
</head>
<body>
<div class="include-before">
</div>
<div class="frontmatter">
<div class="title"><h1>Cross-validation</h1></div>
<div class="author"><h2></h2></div>
<div class="date"><h3></h3></div>
</div>
<div class="body">
<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{Cross-validation}
-->
<h1 id="cross-validation">Cross-validation</h1>
<h2 id="comparing-cross-validation-methods">Comparing cross-validation methods</h2>
<pre><code class="language-r">library(data.table)
n.segments &lt;- 10
seg.mean.vec &lt;- 1:n.segments
data.per.segment &lt;- 10
data.mean.vec &lt;- rep(seg.mean.vec, each=data.per.segment)
n.data &lt;- length(data.mean.vec)
n.validation.sets &lt;- 100
n.folds.vec &lt;- c(10, 2)
prop.valid.vec &lt;- 1/n.folds.vec
sim.result.list &lt;- list()
if(interactive()){
  for(data.seed in 1:100){
    set.seed(data.seed)
    data.vec &lt;- rnorm(n.data, data.mean.vec, 0.1)
    is.valid.vec.list &lt;- list()
    for(n.folds in n.folds.vec){
      uniq.folds &lt;- 1:n.folds
      n.seeds &lt;- n.validation.sets/n.folds
      split.type &lt;- sprintf(&quot;%d-fold %d times&quot;, n.folds, n.seeds)
      for(seed in 1:n.seeds){
        set.seed(seed)
        fold.vec &lt;- sample(rep(uniq.folds, l=n.data))
        for(valid.fold in uniq.folds){
          is.valid.vec.list[[split.type]][[paste(seed, valid.fold)]] &lt;-
            fold.vec==valid.fold
        }
      }
    }
    for(prop.valid in prop.valid.vec){
      split.type &lt;- sprintf(&quot;%d%% %d times&quot;, 100*prop.valid, n.validation.sets)
      prop.vec &lt;- c(subtrain=1-prop.valid, validation=prop.valid)
      for(split.i in 1:n.validation.sets){
        set.seed(split.i)
        is.valid.vec.list[[split.type]][[split.i]] &lt;- binsegRcpp::random_set_vec(
          n.data, prop.vec) == &quot;validation&quot;
      }
    }
    loss.dt &lt;- CJ(split.i=1:n.validation.sets, type=names(is.valid.vec.list))[, {
      is.valid &lt;- is.valid.vec.list[[type]][[split.i]]
      bs.model &lt;- binsegRcpp::binseg_normal(data.vec, is.validation.vec=is.valid)
      bs.model$splits[, data.table(
        segments,
        validation.loss)]
    }, by=.(split.i, type)]
    loss.stats &lt;- loss.dt[, .(
      mean.valid.loss=mean(validation.loss)
    ), by=.(type, segments)]
    select.each.split &lt;- loss.dt[
    , .SD[which.min(validation.loss)],
      by=.(type, split.i)]
    selected.times &lt;- select.each.split[, .(
      times=.N
    ), by=.(type, segments)]
    selected.segments &lt;- rbind(
      select.each.split[, .(
        selected=min(segments)
      ), by=.(method=paste(type, &quot;min err, min segs&quot;))],
      selected.times[, .(
        selected=segments[which.max(times)]
      ), by=.(method=paste(type, &quot;min err, max times&quot;))],
      loss.stats[, .(
        selected=segments[which.min(mean.valid.loss)]
      ), by=.(method=paste(type, &quot;mean err, min err&quot;))]
    )
    sim.result.list[[data.seed]] &lt;- data.table(
      data.seed, selected.segments, n.segments)
  }
  sim.result &lt;- do.call(rbind, sim.result.list)
  (sim.err &lt;- sim.result[, .(
    zero.one.loss=sum(selected != n.segments),
    L1.loss=sum(abs(selected-n.segments)),
    L2.loss=sum((selected-n.segments)^2)
  ), by=method][order(zero.one.loss)])
  plot(data.vec)
}
</code></pre>
<p>The code above compares several types of cross-validation for
selecting the number of segments in simulated random normal data. The
table above shows various error rates which compare the selected
number of segments to the true number of segments in the
simulation. The best methods appears to be the ones which use min err,
max times.</p>
<h2 id="how-many-times-is-sufficient">How many times is sufficient?</h2>
<pre><code class="language-r">n.segments &lt;- 20
seg.mean.vec &lt;- 1:n.segments
data.per.segment &lt;- 5
data.mean.vec &lt;- rep(seg.mean.vec, each=data.per.segment)
n.data &lt;- length(data.mean.vec)
n.validation.sets &lt;- 200
prop.valid &lt;- c(0.01, 0.05, 0.1, 0.25, 0.5)
if(interactive()){
  sim.result &lt;- data.table(data.seed=1:100)[, {
    set.seed(data.seed)
    data.vec &lt;- rnorm(n.data, data.mean.vec, 0.1)
    select.each.split &lt;- CJ(split.i=1:n.validation.sets, prop.valid)[, {
      set.seed(split.i)
      prop.sets &lt;- c(subtrain=1-prop.valid, validation=prop.valid)
      is.valid &lt;- binsegRcpp::random_set_vec(
        n.data, prop.sets)==&quot;validation&quot;
      bs.model &lt;- binsegRcpp::binseg_normal(
        data.vec, is.validation.vec=is.valid)
      bs.model$splits[, .(selected=segments[which.min(validation.loss)])]
    }, by=.(split.i, prop.valid)]
    data.table(n.splits=1:n.validation.sets)[, {
      select.each.split[split.i &lt;= n.splits, .(
        times=.N
      ),
      by=.(prop.valid, selected)
      ][, .SD[which.max(times), .(selected)], by=prop.valid]
    }, by=n.splits]
  }, by=data.seed]

  if(require(ggplot2)){
    ggplot()+
      scale_color_gradient(low=&quot;red&quot;, high=&quot;black&quot;)+
      geom_line(aes(
        n.splits, selected,
        group=paste(data.seed, prop.valid),
        color=prop.valid),
        data=sim.result)+
      scale_y_continuous(breaks=seq(0, 100, by=10))
  }

  accuracy.dt &lt;- sim.result[, .(
    correct=sum(selected==n.segments)
  ), by=.(prop.valid, n.splits)]
  if(require(ggplot2)){
    gg &lt;- ggplot()+
      geom_line(aes(
        n.splits, correct,
        group=prop.valid,
        color=prop.valid),
        size=2,
        data=accuracy.dt)+
      scale_y_continuous(&quot;number of correctly chosen data sets&quot;)+
      scale_color_gradient(low=&quot;red&quot;, high=&quot;black&quot;)
    if(require(directlabels)){
      direct.label(gg, &quot;right.polygons&quot;)
    }else{
      gg
    }
  }
}
</code></pre>
<p>The plot above suggests that 100 validation sets is sufficient.</p>
</div>
<div class="include-after">
</div>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js" defer></script>
</body>
</html>
